{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52eeaf28-c468-4b7f-a9a8-01ba5fdb28a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "\n",
    "N_SIM = 10000\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------\n",
    "# LOAD TABLES\n",
    "# -----------------------\n",
    "\n",
    "demo_users = spark.table(\"workspace.bronze.demo_users\")\n",
    "plans = spark.table(\"workspace.bronze.plans\")\n",
    "\n",
    "# Limit demo to Fulton plans\n",
    "plans_demo = plans.filter(col(\"county\") == \"Fulton\").limit(5)\n",
    "plans_pd = plans_demo.toPandas()\n",
    "\n",
    "users_pd = demo_users.toPandas()\n",
    "\n",
    "# -----------------------\n",
    "# COST DISTRIBUTIONS\n",
    "# -----------------------\n",
    "\n",
    "OFFICE_MEDIAN = 150\n",
    "OFFICE_SIGMA = 0.6\n",
    "\n",
    "ER_MEDIAN = 1200\n",
    "ER_SIGMA = 0.9\n",
    "\n",
    "MED_LOW = (10, 60)\n",
    "MED_HIGH = (100, 600)\n",
    "\n",
    "def lognormal_params(median, sigma):\n",
    "    mu = np.log(median)\n",
    "    return mu, sigma\n",
    "\n",
    "mu_off, sigma_off = lognormal_params(OFFICE_MEDIAN, OFFICE_SIGMA)\n",
    "mu_er, sigma_er = lognormal_params(ER_MEDIAN, ER_SIGMA)\n",
    "\n",
    "results = []\n",
    "\n",
    "# -----------------------\n",
    "# LOOP OVER USERS\n",
    "# -----------------------\n",
    "\n",
    "for _, user in users_pd.iterrows():\n",
    "\n",
    "    user_id = user[\"user_id\"]\n",
    "    med_count = user[\"medication_count\"]\n",
    "    er_lambda = max(user[\"expected_er_visits\"], 0.05)\n",
    "    therapy_lambda = max(user[\"therapy_frequency\"] * 12, 1)\n",
    "\n",
    "    # Medication risk adjustment\n",
    "    high_med_prob = min(0.2 + 0.05 * med_count, 0.6)\n",
    "\n",
    "    # -----------------------\n",
    "    # LOOP OVER PLANS\n",
    "    # -----------------------\n",
    "\n",
    "    for _, plan in plans_pd.iterrows():\n",
    "\n",
    "        deductible = float(plan[\"deductible\"])\n",
    "        oop_max = float(plan[\"oop_max\"]) if plan[\"oop_max\"] else deductible * 2\n",
    "        coinsurance = 0.2\n",
    "\n",
    "        # -------- UTILIZATION --------\n",
    "\n",
    "        office_counts = np.random.poisson(therapy_lambda, N_SIM)\n",
    "        er_counts = np.random.poisson(er_lambda, N_SIM)\n",
    "\n",
    "        med_random = np.random.rand(N_SIM)\n",
    "        med_monthly = np.where(\n",
    "            med_random < (1 - high_med_prob),\n",
    "            np.random.uniform(MED_LOW[0], MED_LOW[1], N_SIM),\n",
    "            np.random.uniform(MED_HIGH[0], MED_HIGH[1], N_SIM)\n",
    "        )\n",
    "        med_total = med_monthly * 12\n",
    "\n",
    "        # -------- COST SAMPLING --------\n",
    "\n",
    "        office_costs = np.array([\n",
    "            np.random.lognormal(mu_off, sigma_off, count).sum()\n",
    "            if count > 0 else 0\n",
    "            for count in office_counts\n",
    "        ])\n",
    "\n",
    "        er_costs = np.array([\n",
    "            np.random.lognormal(mu_er, sigma_er, count).sum()\n",
    "            if count > 0 else 0\n",
    "            for count in er_counts\n",
    "        ])\n",
    "\n",
    "        annual_allowed = office_costs + er_costs + med_total\n",
    "\n",
    "        # -------- OOP CALCULATION --------\n",
    "\n",
    "        oop = np.where(\n",
    "            annual_allowed <= deductible,\n",
    "            annual_allowed,\n",
    "            deductible + coinsurance * (annual_allowed - deductible)\n",
    "        )\n",
    "\n",
    "        oop = np.minimum(oop, oop_max)\n",
    "\n",
    "        # -------- METRICS --------\n",
    "\n",
    "        breach_prob = np.mean(annual_allowed > deductible)\n",
    "        mean_oop = np.mean(oop)\n",
    "        p90 = np.percentile(oop, 90)\n",
    "\n",
    "        results.append((\n",
    "            str(user_id),\n",
    "            str(plan[\"plan_id\"]),\n",
    "            float(breach_prob),\n",
    "            float(mean_oop),\n",
    "            float(p90)\n",
    "        ))\n",
    "\n",
    "# -----------------------\n",
    "# WRITE TO GOLD\n",
    "# -----------------------\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"plan_id\", StringType(), True),\n",
    "    StructField(\"breach_probability\", DoubleType(), True),\n",
    "    StructField(\"mean_oop\", DoubleType(), True),\n",
    "    StructField(\"p90_exposure\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS workspace.gold.monte_carlo_risk_metrics\")\n",
    "\n",
    "gold_mc = spark.createDataFrame(results, schema=schema)\n",
    "\n",
    "gold_mc.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.gold.monte_carlo_risk_metrics\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_gold_monte_carlo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
